# -*- coding: utf-8 -*-
"""Flower_Recognition_PIAIC_91502_April_7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tRnmjMoPYaQsejMMBJlIu31BRykcgTby

Assignment: Flowers Recognition <br>
Dataset Description:<br>

This dataset contains 4242 images of flowers.<br>
The data collection is based on the data flicr, google images, yandex images.<br>
You can use this datastet to recognize plants from the photo.<br>

Attribute Information:<br>
The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>
For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>
<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>
This is a Multiclass Classification Problem.<br>

WORKFLOW : <br>
Load Data <br>
Split into 60 and 40 ratio.<br>
Encode labels.<br>
Create Model<br>
Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>
Train the Model.<br>
If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>
Prediction should be > 85%<br>
Evaluation Step<br>
Prediction<br>

# **Import all necessary Libraries**
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import seaborn as sns
import matplotlib.pyplot as plt
import os
from tensorflow.keras import models, layers, optimizers
from tensorflow.keras.utils import to_categorical

from os import listdir 
# listdir() returns a list containing the names of the entries in the directory given by path. The list is in arbitrary order. It does not include the special entries '. ' and '..' even if they are present in the directory
from os.path import join 
# The Python os. path. join method combines one or more path names into a single path. This method is often used with os methods like os. walk() to create the final path for a file or folder
import cv2 
# OpenCV-Python is a library of Python bindings designed to solve computer vision problems. cv2. imread() method loads an image from the specified file. If the image cannot be read (because of missing file, improper permissions, unsupported or invalid format) then this method returns an empty matrix
import pathlib
# The Pathlib module in Python deals with path related tasks, such as constructing new paths from names of files and from other paths, checking for various properties of paths and creating files and folders at specific paths
from pathlib import Path
# It instantiates a concrete path for the platform the code is running on. ... Pure paths are useful in some special cases; for example: If you want to manipulate Windows paths on a Unix machine (or vice versa).

directory = Path('/content/drive/MyDrive/PIAIC/Flowers')

flowers = []
features = []
labels = []

# Iterating Over Directory To Extract Sub Directories
for dir in directory.iterdir():
  flowers.append(dir.name)
  print(dir.name)
# Iterating Over Sub Directories To Extract Lables
  for imgpath in dir.iterdir():
    if imgpath.name.endswith("jpg"):
      labels.append(dir.name)
      imgarr = cv2.imread(str(imgpath), cv2.IMREAD_GRAYSCALE)
      imgarr = cv2.resize(imgarr, (150,150))
      features.append(imgarr)

from keras.utils import to_categorical
from sklearn.preprocessing import LabelBinarizer, LabelEncoder
labels = LabelEncoder().fit_transform(labels)
labels=to_categorical(labels)

image_names=np.asarray(flowers)
image_names.shape

data = np.asarray(features).reshape(4242,150*150)
data = data.astype("float32")/255.0

import sklearn
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(data,labels,test_size=.40,random_state=1)

from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras import losses,optimizers,regularizers
network =Sequential()
network.add(Dense(256,kernel_regularizer=regularizers.l2(0.001),activation="relu",input_shape=(X_train.shape[1],)))
#network.add(Dropout(0.2))
network.add(Dense(128,kernel_regularizer=regularizers.l2(0.001),activation='relu'))
network.add(Dense(64,kernel_regularizer=regularizers.l2(0.001),activation='relu'))
#network.add(Dropout(0.2))
network.add(Dense(32,kernel_regularizer=regularizers.l2(0.001),activation='relu'))
#network.add(Dropout(0.2))
network.add(Dense(5,activation="softmax"))

network.compile(loss='categorical_crossentropy',optimizer='rmsPROP',metrics=['accuracy'])

batch_size = 20
epochs = 500
history=network.fit(X_train, y_train,batch_size=batch_size,epochs=epochs)

history_dict = history.history
history_dict.keys()
[u'accuracy', u'loss']

import matplotlib.pyplot as plt
history_dict = history.history
loss_values = history_dict['loss']
val_accuracy = history_dict['accuracy']
epochs = range(1, len(history_dict['accuracy']) + 1)
plt.plot(epochs, loss_values, 'r', label='loss')
plt.plot(epochs, val_accuracy, 'b', label='accuracy')
plt.title('loss and accuracy')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()

network.evaluate(X_test,y_test)

pred = network.predict_classes(X_test[:10])
for i in range(len(pred)):
    print(pred[i],'==>',y_test[i])

plt.figure(figsize=(20,5))
plt.subplot(1, 2, 1 )
plt.hist(y_test[:10])
plt.xlabel('original target value')
plt.ylabel('count')
plt.subplot(1, 2, 2)
plt.hist(pred)
plt.xlabel('aggregated target value')
plt.ylabel('count')
plt.show()